Давайте повністю переосмислимо завдання на **Goroutines та Channels**, зробивши їх максимально наближеними до реальної розробки. Ми зосередимося на сценаріях, які часто зустрічаються у бекенд-розробці, системних утилітах або сервісах обробки даних.

---

### Оновлені Завдання на Goroutines та Channels (Реальні Сценарії):

### Завдання 3: Використання `sync.WaitGroup` для очікування завершення Goroutines

**Мета:** Навчитися використовувати `sync.WaitGroup` для того, щоб `main` Goroutine чекала на завершення всіх запущених паралельних Goroutines. Це фундаментальний патерн для координації конкурентних завдань.

**Сценарій:** Уявіть, що ви запускаєте кілька фонових завдань (наприклад, відправку електронних листів, генерацію звітів або завантаження даних), і вам потрібно переконатися, що всі вони завершені, перш ніж програма вийде.

1. **Створіть функцію `worker(id int, messages chan<- string, wg *sync.WaitGroup)`:**
    
    - Параметр `id` буде ідентифікатором воркера (наприклад, 1, 2, 3).
    - Параметр `messages` - це канал для надсилання повідомлень (`chan<- string` - лише для запису).
    - Параметр `wg` - це покажчик на `sync.WaitGroup`.
2. **Всередині функції `worker`:**
    
    - **Важливо:** На самому початку функції `worker`, після її запуску, але перед будь-якими операціями, **викличте `defer wg.Done()`**. Це гарантує, що `wg.Done()` буде викликано, коли функція `worker` завершить свою роботу (нормально чи через паніку).
    - Виведіть у консоль: `Воркер %d: запускається...\n` (замість `%d` підставте `id`).
    - Імітуйте виконання роботи: `time.Sleep(time.Duration(rand.Intn(500)+500) * time.Millisecond)` – випадкова затримка від 500 мс до 1 секунди.
    - Надішліть повідомлення в канал `messages`: `messages <- fmt.Sprintf("Воркер %d: робота завершена!", id)`.
    - Виведіть у консоль: `Воркер %d: завершив роботу.\n`.
3. **У функції `main`:**
    
    - Створіть `sync.WaitGroup` змінну: `var wg sync.WaitGroup`.
    - Створіть буферизований канал `results` (наприклад, розміром 5) для отримання повідомлень від воркерів: `results := make(chan string, 5)`.
    - Визначте кількість воркерів, які ви хочете запустити (наприклад, `numWorkers := 3`).
    - **Перед запуском кожної Goroutine `worker`:**
        - **Викличте `wg.Add(1)`**. Це збільшує лічильник `WaitGroup` на 1.
    - У циклі (`for i := 1; i <= numWorkers; i++`):
        - Запустіть `worker` як Goroutine: `go worker(i, results, &wg)`.
    - **Після запуску всіх воркерів:**
        - **Запустіть окрему Goroutine**, яка буде відповідати за **закриття каналу `results`**. Ця Goroutine повинна спочатку **викликaти `wg.Wait()`**, щоб дочекатися завершення всіх воркерів, а потім **закрити канал `results`**: `close(results)`.
        - Це дуже важливий патерн: **відправник (main Goroutine, яка чекає на воркерів) закриває канал після того, як всі потенційні відправники (воркери) завершать свою роботу.**
    - У `main` Goroutine, **читайте повідомлення з каналу `results` за допомогою циклу `for range`**. Це дозволить вам отримати всі повідомлення від воркерів, поки канал не буде закритий.
    - Виведіть кожне отримане повідомлення.
    - Коли цикл `for range` завершиться (канал `results` закритий), виведіть повідомлення: `Main: Всі воркери завершили роботу і всі результати отримані. Програма завершується.`.

---

**Підказки:**

- Не забувайте імпортувати необхідні пакети: `fmt`, `time`, `sync`, `math/rand` (для `rand.Intn`).
- Завжди ініціалізуйте генератор псевдовипадкових чисел для `rand` за допомогою `rand.Seed(time.Now().UnixNano())` на початку `main` функції, щоб отримувати різні затримки при кожному запуску.

Спробуйте реалізувати це завдання. Це дуже важливий крок до розуміння координації конкурентних завдань у Go!

### Завдання 4: Паралельна Обробка Логів

**Мета:** Навчитися паралельно читати та обробляти рядки з файлу, використовуючи пул "воркерів" (Goroutines), які надсилають результати в центральний канал.

**Сценарій:** Уявіть, що ваш сервіс генерує великий файл логів, і вам потрібно його швидко проаналізувати, щоб виявити певні події або помилки.

1. **Генератор Логів (симуляція):**
    
    - Створіть функцію `generateLogEntries(filename string, count int) error`.
    - Ця функція повинна згенерувати `count` рядків логів і записати їх у файл з назвою `filename`.
    - Кожен рядок логу повинен бути приблизно таким: `YYYY-MM-DD HH:MM:SS [LEVEL] - Message (RequestID: XXXX)`
        - `YYYY-MM-DD HH:MM:SS`: Дата і час.
        - `[LEVEL]`: Випадково `[INFO]`, `[WARN]`, `[ERROR]`.
        - `Message`: Випадковий текст, наприклад, "User logged in", "File not found", "Database connection error".
        - `RequestID: XXXX`: Випадковий ID запиту (наприклад, UUID або просто унікальне число).
    - Після запису всіх логів, закрийте файл.
2. **Читач Логів:**
    
    - Створіть функцію `readLogEntries(filename string, lines chan<- string)`.
    - Ця функція повинна відкрити `filename`, читати його рядок за рядком.
    - Кожен прочитаний рядок відправляти в канал `lines`.
    - Після прочитання всього файлу, **закрийте канал `lines`**. Це буде сигналом для воркерів, що більше даних не буде.
3. **Воркер-Аналізатор Логів:**
    
    - Створіть функцію `logAnalyzer(id int, in <-chan string, errors chan<- string, wg *sync.WaitGroup)`.
    - Запустіть цю функцію як Goroutine (це буде наш "воркер").
    - Кожен воркер читає рядки з каналу `in` за допомогою `for range`.
    - Для кожного рядка логу:
        - Симулюйте "обробку" логу за допомогою `time.Sleep(5 * time.Millisecond)`.
        - **Перевірте, чи містить рядок логу підрядок `"[ERROR]"`**.
        - Якщо містить `"[ERROR]"`, надішліть весь цей рядок у канал `errors`.
        - Виведіть у консоль: `Воркер X: обробив рядок <перші 30 символів рядка>...`
    - Після виходу з циклу `for range` (коли канал `in` закриється), воркер повинен викликати `wg.Done()`.
4. **Головна Логіка (`main` функція):**
    
    - Визначте ім'я файлу логів (наприклад, `"app.log"`) та кількість рядків (наприклад, `1000`).
    - **Викличте `generateLogEntries`** для створення файлу логів.
    - Створіть канал `logLines` (для передачі рядків логів від читача до аналізаторів). Зробіть його **буферизованим** (наприклад, розміром `100`).
    - Створіть канал `errorLogs` (для отримання помилкових логів від аналізаторів). Зробіть його **буферизованим** (наприклад, розміром `50`).
    - Створіть `sync.WaitGroup`.
    - **Запустіть `readLogEntries` як Goroutine.**
    - **Запустіть 5 Goroutines `logAnalyzer`** (наш пул воркерів). Додайте `5` до `wg` для цих воркерів.
    - **У `main` Goroutine:**
        - Запустіть окрему Goroutine для читання з каналу `errorLogs` за допомогою `for range` і виведення кожного отриманого рядка.
        - Після того, як `readLogEntries` закриє `logLines`, **дочекайтеся завершення всіх `logAnalyzer` Goroutines за допомогою `wg.Wait()`**.
        - **Після того, як всі воркери завершили роботу, закрийте канал `errorLogs`**. Це дозволить Goroutine, що читає помилки, завершити роботу.
    - Додайте невелику затримку або ще один `WaitGroup` для Goroutine, яка читає помилки, щоб переконатися, що всі помилки виведені перед завершенням програми.

---

### Завдання 5: Обробка Запитів до API з Таймаутом

**Мета:** Практика використання `select` для обробки таймаутів при роботі з мережевими запитами, імітуючи відповіді зовнішнього сервісу.

**Сценарій:** Ви маєте сервіс, який відправляє запити до іншого API і повинен коректно обробляти випадки, коли відповідь надходить занадто довго.

1. **Симулятор Зовнішнього API:**
    
    - Створіть функцію `simulateExternalAPI(requestID string, responseChan chan<- string, timeout int)`.
    - Ця функція симулює мережевий запит:
        - Вона запускається як Goroutine.
        - Генерує випадкову затримку `time.Sleep` **від 1 до `timeout` секунд**.
        - Після затримки надсилає рядок "Response for RequestID: `requestID` - Success!" або "Response for RequestID: `requestID` - Failed!" (з ймовірністю 80%/20%) у `responseChan`.
        - **Важливо:** Не закривайте `responseChan` всередині цієї функції.
2. **Генератор Запитів:**
    
    - Створіть функцію `requestGenerator(requestIDs chan<- string, count int)`.
    - Генеруйте `count` унікальних `requestID` (можна просто "req_1", "req_2", ...).
    - Відправляйте кожен `requestID` у канал `requestIDs`.
    - Після генерації всіх `requestID`, закрийте канал `requestIDs`.
3. **Обробник Запитів:**
    
    - Створіть функцію `processRequest(requestID string, apiResponse chan string)`.
    - Ця функція запускає `simulateExternalAPI` як Goroutine.
    - **Використовує `select`** для очікування або відповіді від `apiResponse`, або спрацьовування таймауту.
    - Якщо відповідь прийшла: виводить `[Успіх] Запит <requestID>: <відповідь>`.
    - Якщо спрацював таймаут (наприклад, 1.5 секунди): виводить `[Таймаут] Запит <requestID> не отримав відповіді вчасно.`.
    - Виклик `processRequest` повинен бути синхронним з `main` або використовувати WaitGroup.
4. **Головна Логіка (`main` функція):**
    
    - Визначте кількість запитів (наприклад, `10`).
    - Створіть канал `requestIDs` (для передачі ID запитів).
    - Створіть `sync.WaitGroup`.
    - Запустіть `requestGenerator` як Goroutine.
    - Створіть цикл `for range` для читання `requestID` з каналу `requestIDs`.
    - Усередині циклу:
        - Для кожного `requestID`, створіть **новий буферизований канал** `apiResponse` (розміром 1). Це важливо, оскільки кожен запит потребує власного каналу для відповіді.
        - Запустіть `processRequest(requestID, apiResponse)` як Goroutine.
        - Додайте `wg.Add(1)` перед запуском Goroutine, і `wg.Done()` всередині `processRequest` після її завершення.
    - Після циклу, викличте `wg.Wait()` для очікування завершення всіх обробників.

---

### Завдання 6: Паралельне Завантаження Даних та Агрегація

**Мета:** Застосувати патерни Fan-Out (розподіл завдань) та Fan-In (збір результатів) для симуляції паралельного завантаження даних із різних джерел та їх агрегації.

**Сценарій:** Вашому додатку потрібно зібрати дані про товари з кількох зовнішніх мікросервісів або джерел даних (наприклад, ціна з одного API, опис з іншого, наявність з третього) та об'єднати їх в один об'єкт.

1. **Структури Даних:**
    
    - Визначте структуру `ProductRequest` з полем `ID string`.
    - Визначте структуру `ProductPartialData` з полями `ID string`, `Source string`, `Data string` (або `Price float64`, `Description string`, `Availability bool` для конкретики).
    - Визначте структуру `Product` з полями `ID string`, `Price float64`, `Description string`, `Availability bool`.
2. **Генератор Запитів на Товари:**
    
    - Створіть функцію `generateProductRequests(out chan<- ProductRequest, count int)`.
    - Генерує `count` запитів `ProductRequest` з унікальними ID (наприклад, "prod_001", "prod_002", ...).
    - Відправляє їх у канал `out` і закриває канал після всіх запитів.
3. **Воркери Завантаження Даних (Fan-Out):**
    
    - Створіть три функції, кожна з яких симулює завантаження даних з різного джерела:
        - `fetchPrice(in <-chan ProductRequest, out chan<- ProductPartialData, wg *sync.WaitGroup)`
        - `fetchDescription(in <-chan ProductRequest, out chan<- ProductPartialData, wg *sync.WaitGroup)`
        - `fetchAvailability(in <-chan ProductRequest, out chan<- ProductPartialData, wg *sync.WaitGroup)`
    - Кожна функція:
        - Читає `ProductRequest` з `in` каналу за допомогою `for range`.
        - Симулює затримку `time.Sleep` (наприклад, 50-150 мс) для імітації мережевого запиту.
        - Створює `ProductPartialData` з `ID` запиту, відповідним `Source` ("PriceAPI", "DescService", "StockDB") та випадковими "даними".
        - Відправляє `ProductPartialData` у канал `out`.
        - Після завершення (`in` канал закрився), викликає `wg.Done()`.
4. **Агрегатор Даних (Fan-In):**
    
    - Створіть функцію `aggregateProductData(priceChan, descChan, availChan <-chan ProductPartialData, finalProducts chan<- Product, numProducts int, wg *sync.WaitGroup)`.
    - Ця функція отримує **три вхідні канали** (для ціни, опису, наявності) та один вихідний канал `finalProducts`.
    - Використовує **карту** для тимчасового зберігання часткових даних за `ProductRequest.ID`: `map[string]*Product`.
    - У нескінченному циклі `for` з `select` вона читає з усіх трьох вхідних каналів.
    - Коли надходять всі три частини даних для одного `Product.ID`, вона формує повний `Product` об'єкт і відправляє його в канал `finalProducts`.
    - Ця функція повинна знати загальну кількість очікуваних продуктів (`numProducts`), щоб коректно завершити роботу, або використовувати додатковий механізм синхронізації (наприклад, закриття каналів і WaitGroup).
    - Після агрегації всіх продуктів, закриває канал `finalProducts` і викликає `wg.Done()`.
5. **Головна Логіка (`main` функція):**
    
    - Визначте `numProducts = 10`.
    - Створіть канал `productRequests` (буферизований).
    - Створіть окремі канали `priceDataChan`, `descriptionDataChan`, `availabilityDataChan` (всі буферизовані) для часткових даних.
    - Створіть канал `finalProductsChan` для агрегованих результатів.
    - Створіть `sync.WaitGroup` для координації.
    - Запустіть `generateProductRequests` як Goroutine.
    - Запустіть **три Goroutines-воркери**: `fetchPrice`, `fetchDescription`, `fetchAvailability`. Кожна з них читає з `productRequests` і пише у свій відповідний канал. Додайте `wg.Add(3)` для цих воркерів.
    - Запустіть `aggregateProductData` як Goroutine. Додайте `wg.Add(1)` для агрегатора.
    - У `main` функції:
        - Після того, як `generateProductRequests` завершиться, **закрийте `productRequests`**.
        - Дочекайтеся `wg.Wait()` для всіх воркерів завантаження.
        - **Після цього, закрийте канали `priceDataChan`, `descriptionDataChan`, `availabilityDataChan`**. Це дозволить агрегатору завершити роботу.
        - Дочекайтеся `wg.Wait()` для агрегатора.
        - Нарешті, прочитайте та виведіть усі `Product` об'єкти з `finalProductsChan` за допомогою `for range`.

---

Ці завдання набагато ближчі до реальних сценаріїв і допоможуть вам зрозуміти, як ефективно використовувати конкурентність для обробки потоків даних, імітації зовнішніх взаємодій та агрегації результатів.